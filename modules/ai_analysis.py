"""
Module 2: AI Analysis Engine
Classifies uploaded media into:
- üü¢ Real & Safe
- üî¥ Deepfake / Manipulated
- üü° Real but Sensitive (Private)
"""

import numpy as np
import os
import joblib
import cv2
from typing import Dict, Any, Optional
from PIL import Image
import streamlit as st

# For MVP, we'll use rule-based detection with ML-ready structure
# In production, this would use a trained CNN model


class AIAnalysisEngine:
    """AI-powered analysis engine for media classification"""
    
    def __init__(self):
        # ML Model paths
        self.deepfake_model_path = "models/deepfake_model.pkl"
        self.deepfake_model = None
        
        # Initialize Haar Cascade for Face Detection
        try:
            cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            self.face_cascade = cv2.CascadeClassifier(cascade_path)
        except Exception as e:
            print(f"Error initializing face cascade: {e}")
            self.face_cascade = None
            
        self._load_models()

    def _load_models(self):
        """Load the trained ML models if they exist."""
        try:
            if os.path.exists(self.deepfake_model_path):
                self.deepfake_model = joblib.load(self.deepfake_model_path)
                print("ML model for deepfake detection loaded successfully.")
        except Exception as e:
            print(f"Error loading deepfake model: {e}")
    
    def analyze(self, media_data: Dict[str, Any], 
                check_deepfake: bool = True,
                check_sensitive: bool = True) -> Dict[str, Any]:
        """
        Analyze media and return classification results.
        
        Returns:
            {
                'classification': 'real_safe' | 'deepfake' | 'sensitive',
                'confidence': float (0-100),
                'details': {...},
                'recommendations': [...]
            }
        """
        image = media_data.get('image')
        if image is None:
            return {
                'classification': 'unknown',
                'confidence': 0.0,
                'details': {'error': 'No image data available'},
                'recommendations': []
            }
        
        # Convert to RGB if needed
        if image.mode != 'RGB':
            image = image.convert('RGB')
        
        # Convert to numpy array for analysis
        img_array = np.array(image)
        
        results = {
            'deepfake_score': 0.0,
            'sensitive_score': 0.0,
            'manipulation_indicators': [],
            'sensitive_indicators': []
        }
        
        # Deepfake Detection (Rule-based for MVP, ML-ready structure)
        if check_deepfake:
            deepfake_result = self._detect_deepfake(img_array, image)
            results['deepfake_score'] = deepfake_result['score']
            results['manipulation_indicators'] = deepfake_result['indicators']
            results['deepfake_ml_applied'] = deepfake_result.get('ml_applied', False)
        
        # Sensitive Content Detection
        if check_sensitive:
            sensitive_result = self._detect_sensitive_content(img_array, image)
            results['sensitive_score'] = sensitive_result['score']
            results['sensitive_indicators'] = sensitive_result['indicators']
        
        # Determine final classification
        classification, confidence, details = self._classify_results(results)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(classification, results)
        
        return {
            'classification': classification,
            'confidence': confidence,
            'details': {
                'deepfake_score': results['deepfake_score'],
                'sensitive_score': results['sensitive_score'],
                'indicators': {
                    'manipulation': results['manipulation_indicators'],
                    'sensitive': results['sensitive_indicators']
                },
                'ml_applied': results.get('deepfake_ml_applied', False)
            },
            'recommendations': recommendations
        }
    
    def _detect_deepfake(self, img_array: np.ndarray, image: Image.Image) -> Dict[str, Any]:
        """
        Detect deepfake/manipulation indicators.
        MVP: Rule-based detection with ML-ready structure.
        """
        indicators = []
        score = 0.0
        ml_prediction_used = False
        
        # 1. Face Detection Guard
        has_face = False
        if self.face_cascade is not None:
            try:
                # Convert PIL to CV2 format (BGR)
                open_cv_image = np.array(image.convert('RGB'))[:, :, ::-1].copy()
                gray = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)
                # Max strictness for MVP
                # minNeighbors 10 (very high - requires lots of confirmation)
                # scaleFactor 1.4 (larger steps = less chance of noise matching)
                faces = self.face_cascade.detectMultiScale(gray, 1.4, 10, minSize=(120, 120))
                
                # Heuristic: If we detect 10+ faces in a single upload, it's likely text/code noise
                if 0 < len(faces) < 8:
                    has_face = True
                elif len(faces) >= 8:
                    indicators.append("üõ°Ô∏è Face Detection Gate: Pattern noise detected (too many 'faces').")
                    indicators.append("‚ÑπÔ∏è Likely non-facial content (code/text) - analysis skipped.")
                else:
                    indicators.append("üõ°Ô∏è Face Detection Gate: No human face detected in image.")
                    indicators.append("‚ÑπÔ∏è Deepfake analysis skipped to prevent false positives on non-facial content.")
            except Exception as e:
                print(f"Face detection error: {e}")
                # Fallback to true to allow ML if detection fails
                has_face = True 

        # 2. Pure ML detection (only if face is detected)
        if has_face and self.deepfake_model:
            try:
                # Preprocess for the model (same as training: 64x64 flat)
                img_resized = image.resize((64, 64)).convert('RGB')
                img_flat = np.array(img_resized).flatten() / 255.0
                
                # Get probability
                probs = self.deepfake_model.predict_proba([img_flat])[0]
                # Label 1 is Fake (from training script)
                score = probs[1] * 100
                ml_prediction_used = True
                
                # Machine-readable reason converted to human-readable
                if score > 70:
                    indicators.append("Model detected strong mathematical signatures of synthetic manipulation.")
                    indicators.append("Pattern match found with known deepfake noise characteristics.")
                elif score > 30:
                    indicators.append("Model identified subtle inconsistencies in image structure.")
                else:
                    indicators.append("Model identified natural sensor noise patterns typical of original media.")
            except Exception as e:
                indicators.append(f"ML Analysis error: {str(e)}")
        elif not has_face:
            # Face detection specifically failed to find a face
            score = 0.0
        elif not self.deepfake_model:
            indicators.append("ML Model not loaded - deepfake detection inactive.")
        
        return {
            'score': min(score, 100.0),
            'indicators': indicators,
            'ml_applied': ml_prediction_used
        }
    
    def _detect_sensitive_content(self, img_array: np.ndarray, image: Image.Image) -> Dict[str, Any]:
        """
        Detect sensitive/private content.
        MVP: Rule-based with ML-ready structure.
        """
        indicators = []
        score = 0.0
        
        # In production, this would use:
        # - Face detection and recognition
        # - Nudity detection models
        # - Context analysis
        # - User-provided flags
        
        # For MVP, this is conceptual
        # User can manually flag content as sensitive
        
        return {
            'score': score,
            'indicators': indicators
        }
    
    def _classify_results(self, results: Dict[str, Any]) -> tuple:
        """
        Classify media based on analysis results.
        Returns: (classification, confidence, details)
        """
        deepfake_score = results['deepfake_score']
        sensitive_score = results['sensitive_score']
        
        # Classification logic with "Human-Realistic" capping (max 98%)
        if deepfake_score > 50:
            classification = 'deepfake'
            # Cap confidence at 98.5% to avoid appearing "too perfect"
            confidence = min(deepfake_score, 98.5)
            details = "High likelihood of manipulation or deepfake" if deepfake_score > 75 else "Signs of potential image manipulation detected"
        elif sensitive_score > 40:
            classification = 'sensitive'
            confidence = min(sensitive_score, 98.0)
            details = "Content appears to be sensitive/private"
        else:
            classification = 'real_safe'
            # If no face was detected, we are confident it's not a deepfake, but use a realistic cap
            raw_confidence = 100 - max(deepfake_score, sensitive_score)
            confidence = min(raw_confidence, 98.0)
            
            # Check if face gate triggered
            face_gate_triggered = any("Face Detection Gate" in ind for ind in results.get('manipulation_indicators', []))
            if face_gate_triggered:
                details = "Authentic (Non-facial content detected)"
            else:
                details = "Content appears to be authentic and safe"
        
        return classification, confidence, details
    
    def _generate_recommendations(self, classification: str, results: Dict[str, Any]) -> list:
        """Generate recommendations based on classification"""
        recommendations = []
        
        if classification == 'deepfake':
            recommendations.extend([
                "‚ö†Ô∏è This content shows signs of manipulation",
                "üîç Verify source before sharing",
                "üõ°Ô∏è Consider reporting if used maliciously"
            ])
        elif classification == 'sensitive':
            recommendations.extend([
                "üîí This content may be sensitive",
                "üõ°Ô∏è Consider generating protection fingerprint",
                "‚ö†Ô∏è Be cautious about sharing"
            ])
        else:
            recommendations.extend([
                "‚úÖ Content appears authentic",
                "üìù No immediate concerns detected"
            ])
        
        return recommendations

